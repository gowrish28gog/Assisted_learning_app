{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gujar.p/Documents/Data Science Capstone/capstone_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who was the AFC champion in Super Bowl 50?',\n",
       " 'What was the final score of the Denver Broncos and Carolina Panthers?',\n",
       " 'In what year did Super Bowl 50 take place?',\n",
       " 'Where was Super Bowl 50 played?',\n",
       " 'Why were Roman numerals not used for Super Bowl 50?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prompt = \"\"\"\n",
    "Generate 5 basic questions based on the following context. Please give questions only and eliminate all kinds of other text. Please exclude question numbers as well.:\n",
    "Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. \n",
    "The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. \n",
    "The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. \n",
    "As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": full_prompt}])\n",
    "\n",
    "generated_questions = response['message']['content'].split('\\n')\n",
    "\n",
    "generated_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "references = [\n",
    "    \"What team was the AFC champion?\",\n",
    "    \"What was the final score of Super Bowl 50?\",\n",
    "    \"What year was Super Bowl 50?\", \n",
    "    \"Where did Super Bowl 50 take place?\",\n",
    "    \"What was the theme of Super Bowl 50?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c68b29f3c1c445dbcfc07acbea9a7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': [0.915608823299408,\n",
       "  0.9318769574165344,\n",
       "  0.9346223473548889,\n",
       "  0.9743198752403259,\n",
       "  0.9045952558517456],\n",
       " 'recall': [0.9390940070152283,\n",
       "  0.9383586645126343,\n",
       "  0.9631624221801758,\n",
       "  0.9639801979064941,\n",
       "  0.9426460266113281],\n",
       " 'f1': [0.9272027611732483,\n",
       "  0.9351065754890442,\n",
       "  0.9486777782440186,\n",
       "  0.9691224694252014,\n",
       "  0.9232287406921387],\n",
       " 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.49.0)'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=generated_questions, references=references, lang=\"en\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.9322\n",
      "Average Recall: 0.9494\n",
      "Average F1: 0.9407\n"
     ]
    }
   ],
   "source": [
    "avg_precision = sum(results['precision']) / len(results['precision'])\n",
    "avg_recall = sum(results['recall']) / len(results['recall'])\n",
    "avg_f1 = sum(results['f1']) / len(results['f1'])\n",
    "\n",
    "# Print the average values\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1: {avg_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
